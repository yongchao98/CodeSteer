<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Steering Large Language Models between Code Execution and Textual Reasoning">
  <meta name="keywords" content="prompt optimization, natural language processing, Large Language Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Steering Large Language Models between Code Execution and Textual Reasoning</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  
  <style>
    .simulation-image {
      height: 340px;
      width: 500px;
    }
  </style>
  
  <style>
    .table-image {
      height: 260px;
      width: 500px;
    }
  </style>
  
  <style>
    .abstract-content {
      max-width: 900px;
      margin: 0 auto;
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://realm.mit.edu">
            REALM Website
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Steering Large Language Models between Code Execution and Textual Reasoning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yongchao98.github.io/YongchaoChen/">Yongchao Chen</a>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/view/harshjhamtani/home">Harsh Jhamtani</a>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=en&user=szcf_iUAAAAJ">Srinagesh Sharma</a>,
            </span>
            <span class="author-block">
              <a href="http://chuchu.mit.edu">Chuchu Fan</a>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/chi-wang-49b15b16/">Chi Wang</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">MIT, Harvard, Microsoft Research, Google DeepMind</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1wRdtIG4raYd-Ts5sI5ieHMXUl7BkuKGv/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Website Link. -->
              <span class="link-block">
                <a href="https://yongchao98.github.io/CodeSteer/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-link"></i>
                  </span>
                  <span>Website</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://yongchao98.github.io/CodeSteer/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code and Dataset will be out soon</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/LLM-makes-simple-mistakes-gather.png"
        class="center-image"
        alt=""/>
      <h2 class="subtitle has-text-centered" style="color: red;">
        <br/>
        GPT-4o makes simple mistakes by direct textual reasoning but can reliably solve the problem with prompted to use code. Our research highlights the limitations of textual reasoning in LLMs for tasks involving math, logic, and optimization, where code generation offers a more scalable solution. Despite advances like OpenAI's GPT Code Interpreter and AutoGen, no optimal method exists to reliably steer LLMs between code and text generation. This study identifies key patterns in how LLMs choose between code and text with various factors and proposes three methods to improve steering.
        </h2>     
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified abstract-content">
          <p>
           While a lot of recent research focuses on enhancing the textual reasoning capabilities of Large Language Models (LLMs) by optimizing the multi-agent framework or reasoning chains, several benchmark tasks can be solved with 100% success through direct coding, which is more scalable and avoids the computational overhead associated with textual iterating and searching. Textual reasoning has inherent limitations in solving tasks with challenges in math, logics, optimization, and searching, which is unlikely to be solved by simply scaling up the model and data size. The recently released OpenAI GPT Code Interpreter and multi-agent frameworks such as AutoGen have demonstrated remarkable proficiency of integrating code generation and execution to solve complex tasks using LLMs. However, based on our experiments on 7 existing popular methods for steering code/text generation in both single- and multi-turn settings with 14 tasks and 6 types of LLMs (including the new O1-preview), currently there is no optimal method to correctly steer LLMs to write code when needed. 
          </p>
          <p>
           We discover some interesting patterns on when models use code vs. textual reasoning with the evolution to task complexity and model sizes, which even result in an astonishingly inverse scaling law. We also discover that results from LLM written code are not always better than using textual reasoning, even if the task could be solved through code. To mitigate the above issues, we propose three methods to better steer LLM code/text generation and achieve a notable improvement. The costs of token lengths and runtime are thoroughly discussed for all the methods. We believe the problem of steering LLM code/text generation is critical for future research and has much space for further improvement.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="Table1">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/Evolution-with-complexity-number-multiply.png"
        class="center-image"
        alt=""/> 
    </div>
  </div>
</section>

<section class="Table1">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/number_multiply_code_inter.png"
        class="center-image"
        alt=""/> 
    </div>
  </div>
</section>

<section class="Full prompt part1">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/game24_code_inter.png"
        class="center-image"
        alt=""/> 
        <p>
        Inverse scaling law of model sizes and evolution with task complexity.
        </p>     
    </div>
  </div>
</section>

<section class="Table1">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/code_answer_gpt3-4mini.png"
        class="center-image"
        alt=""/> 
    </div>
  </div>
</section>

<section class="Full prompt part2">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/game24_code_success_rate.png"
        class="center-image"
        alt=""/> 
        <h2 class="subtitle has-text-centered" style="color: red;">
        <br/>
        Requiring LLMs to answer with code is not always effective.
        </h2>     
    </div>
  </div>
</section>

<section class="Full prompt part2">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/table1-three-llm.png"
        class="center-image"
        alt=""/>    
    </div>
  </div>
</section>

<section class="Full prompt part2">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/table2-gather-6llm.png"
        class="center-image"
        alt=""/>  
    </div>
  </div>
</section>

<section class="Full prompt part1">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/multi-turn-score.png"
        class="center-image"
        alt=""/> 
        <p>
        Multi-turn execution/self-refinement can improve the performance, but depends on the task complexity and LLM capability.
        </p>     
    </div>
  </div>
</section>

<section class="Full prompt part1">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/cost-score.png"
        class="center-image"
        alt=""/> 
        <p>
        Performance vs. Token Length and Performance vs. Runtime.
        </p>     
    </div>
  </div>
</section>

<section class="Full prompt part1">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/boxlift-code-text-answer.png"
        class="center-image"
        alt=""/> 
        <p>
        Example in BoxLift task why requiring LLMs to answer with code is not always effective.
        </p>     
    </div>
  </div>
</section>

<section class="Full prompt part1">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/date-understand-code-text-answer.png"
        class="center-image"
        alt=""/> 
        <p>
        Example in Date Understanding task why requiring LLMs to answer with code is not always effective.
        </p>     
    </div>
  </div>
</section>

<section class="Full prompt part1">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./Webpage/code_answer_example.png"
        class="center-image"
        alt=""/> 
        <p>
        Example in Game24 task why requiring LLMs to answer with code is not always effective.
        </p>     
    </div>
  </div>
</section>
  
<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title">Related Links</h2>
    <div class="content has-text-justified">
      <p>
        This paper focuses on general Foundation Model based Intelligent Agents for virtual and real robots. This work is also part of a broader research thread around <emph>language-instructed task and motion planning</emph>, which allows us to transform from natural language instruction into robot control signals.
      </p>
      <p>
        Other work on Large Language Models to Robot Task and Motion Planning and LLM-based agents from our lab include:
        <ul>
          <li><a href="https://arxiv.org/pdf/2305.07766.pdf">NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models (EMNLP'2023)</a>.</li>
          <li><a href="https://arxiv.org/pdf/2306.06531.pdf">AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers (ICRA'2024)</a>.</li>
          <li><a href="https://arxiv.org/abs/2309.15943.pdf">Scalable Multi-Robot Collaboration with Large Language Models: Centralized or Decentralized Systems? (ICRA'2024)</a>.</li>
          <li><a href="https://arxiv.org/pdf/2402.08702">PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling (EMNLP'2024)</a>.</li>
        </ul>
      </p>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{chen2024steeringlargelanguagemodels,
      title={Steering Large Language Models between Code Execution and Textual Reasoning}, 
      author={Yongchao Chen and Harsh Jhamtani and Srinagesh Sharma and Chuchu Fan and Chi Wang},
      year={2024},
      eprint={2410.03524},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.03524}, 
}
</code></pre>
  </div>
</section>
  
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


</body>
</html>
